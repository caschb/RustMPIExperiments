# -*- org-confirm-babel-evaluate: nil; -*-
#+title: Rust MPI Experiments
#+author: Christian Asch

* Setting up repositories

#+begin_src bash :results output :exports both
git submodule update --init --recursive
#+end_src

This will clone the following repos:

+ [[https://gitlab.com/CNCA_CeNAT/bs-solctra-implementations.git][BS-Solctra Implementations]]: The original C++ MPI+OpenMP
  implementation of BS-Solctra
+ [[https://github.com/caschb/bs-solctra-mpi-rs][BS-Solctra-mpi-rs]]: My Rust+Rayon+MPI implementation of BS-Solctra
+ [[https://github.com/caschb/Kernels][Kernels]]: My fork of the Parallel Research Kernels which include the
  Rust MPI code of the PIC simulation



** Setting up C compiler for Kernels
#+begin_src bash :dir Kernels/common
module load mpich/3.3.2-gcc-9.3.0 gcc/9.3.0
cp make.defs.gcc make.defs
sed -i 's/^MPIDIR=.*/MPIDIR=\/opt\/tools\/mpich-3.3.2-gcc-9.3.0/' make.defs
#+end_src

#+RESULTS:

* Compiling BS-SOLCTRA MPI

We have to change the Makefile so it works on the =kura= nodes

#+begin_src bash :dir bs-solctra-implementations
yes input_1000.txt | head -n 10 | xargs cat > input_big.txt
#+end_src

#+RESULTS:

#+begin_src bash :results output :exports both
FILE=bs-solctra-implementations/Makefile
sed -i 's/^VECT_FLAGS=.*/VECT_FLAGS=-fopenmp/' $FILE
#+end_src

#+begin_src bash :results output :exports both :dir bs-solctra-implementations
module load mpich/3.3.2-gcc-9.3.0 gcc/9.3.0
make
#+end_src

#+RESULTS:
: mpicxx -O3 -std=c++11 -fopenmp -o bs-solctra-multinode solctra_multinode.h solctra_multinode.cpp main_multinode.cpp utils.h utils.cpp
: cp bs-solctra-multinode results
: rm bs-solctra-multinode;

* Compiling BS-SOLCTRA Rust+MPI

#+begin_src bash :dir bs-solctra-mpi-rs/tests/test-resources
tail -n +2 input_1000.csv > temp_file
echo "" >> temp_file
echo x,y,z > input_big.csv
yes temp_file | head -n 10 | xargs cat >> input_big.csv
rm temp_file
#+end_src

#+RESULTS:

#+begin_src bash :dir bs-solctra-mpi-rs/tests/test-resources
head input_big.csv
#+end_src

#+RESULTS:
|                   x |   y | z |
|          0.14557183 | 0.0 | 0 |
|          0.14746016 | 0.0 | 0 |
| 0.14934849000000003 | 0.0 | 0 |
| 0.15123682000000002 | 0.0 | 0 |
| 0.15312515000000002 | 0.0 | 0 |
|          0.15501348 | 0.0 | 0 |
| 0.15690181000000003 | 0.0 | 0 |
| 0.15879014000000002 | 0.0 | 0 |
| 0.16067847000000002 | 0.0 | 0 |

#+RESULTS:

#+begin_src bash :results output :exports both :dir bs-solctra-mpi-rs
module load mpich/3.3.2-gcc-9.3.0 gcc/9.3.0
. /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
cargo build -r -j 15
#+end_src

* Compiling PIC C+MPI

#+begin_src bash :results output :exports both :dir Kernels/MPI1/PIC-static
module load mpich/3.3.2-gcc-9.3.0 gcc/9.3.0
make pic
#+end_src

#+RESULTS:
: /opt/tools/mpich-3.3.2-gcc-9.3.0/bin/mpicc -O3 -mtune=native -ffast-math -g3 -Wall   -DMPI -DVERBOSE=0   -DRESTRICT_KEYWORD=0  -I../../include -c pic.c
: /opt/tools/mpich-3.3.2-gcc-9.3.0/bin/mpicc -O3 -mtune=native -ffast-math -g3 -Wall   -DMPI -DVERBOSE=0   -DRESTRICT_KEYWORD=0  -I../../include -c ../../common/MPI_bail_out.c
: /opt/tools/mpich-3.3.2-gcc-9.3.0/bin/mpicc -O3 -mtune=native -ffast-math -g3 -Wall   -DMPI -DVERBOSE=0   -DRESTRICT_KEYWORD=0  -I../../include -c ../../common/wtime.c
: /opt/tools/mpich-3.3.2-gcc-9.3.0/bin/mpicc -O3 -mtune=native -ffast-math -g3 -Wall   -DMPI -DVERBOSE=0   -DRESTRICT_KEYWORD=0  -I../../include -c ../../common/random_draw.c
: /opt/tools/mpich-3.3.2-gcc-9.3.0/bin/mpicc -o pic   -O3 -mtune=native -ffast-math -g3 -Wall   -DMPI pic.o MPI_bail_out.o wtime.o random_draw.o  -lm

* Compiling PIC Rust+MPI

#+begin_src bash :results output :exports both :dir Kernels/RUST/pic-mpi
module load mpich/3.3.2-gcc-9.3.0 gcc/9.3.0
. /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
cargo build -r
#+end_src

#+RESULTS:

* Experiments
** Common components for SLURM files

*** Header

We prepare the heading of all SLURM Files
#+begin_src bash :noweb-ref header
#SBATCH --partition=kura-all
#SBATCH --output=%x_%j.out
#SBATCH --error=%x_%j.err
#SBATCH --time=12:00:00
#SBATCH --ntasks-per-node=20
#SBATCH --cpus-per-task=1
#SBATCH --exclusive
#+end_src

*** Load modules

#+begin_src bash :noweb-ref modules
module purge
module load mpich/3.3.2-gcc-9.3.0 gcc/9.3.0
#+end_src

*** Kura module fix

#+begin_src bash :noweb-ref kura-fix
. /opt/Modules/3.2.10/init/sh
#+end_src

** BS-SOLCTRA MPI+OpenMP Weak Scaling
*** Job Name

#+begin_src bash :noweb-ref bsmo-name
#SBATCH --job-name solc-cpp-ws
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref bsmo-command
export OMP_NUM_THREADS=${SLURM_NTASKS_PER_NODE}
export OMP_SCHEDULE=dynamic
export REPETITIONS=10
TOTAL_PARTICLES=$((${SLURM_NNODES}*3968))
for (( i = 0; i < ${REPETITIONS}; i++))
do
    srun -n ${SLURM_NNODES}\
	    ./bs-solctra-multinode\
	    -length ${TOTAL_PARTICLES}\
	    -particles input_big.txt\
	    -id ${SLURM_JOB_ID}${i}\
	    -resource resources/\
	    -mode 1\
	    -magnetic_prof 0 100 0 2\
	    -print_typef 1\
	    -steps 1000
done
#+end_src

*** Assemble Slurm files for weak scaling and copy files

**** 1 node

#+begin_src bash :dir sol-mpi-wk/1/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-wk/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<bsmo-name>>
<<kura-fix>>
<<modules>>
<<bsmo-command>>
#+end_src

**** 2 nodes

#+begin_src bash :dir sol-mpi-wk/2/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-wk/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<bsmo-name>>
<<kura-fix>>
<<modules>>
<<bsmo-command>>
#+end_src

**** 4 nodes

#+begin_src bash :dir sol-mpi-wk/4/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-wk/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<bsmo-name>>
<<kura-fix>>
<<modules>>
<<bsmo-command>>
#+end_src

**** 8 nodes
#+begin_src bash :dir sol-mpi-wk/8/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-wk/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<bsmo-name>>
<<kura-fix>>
<<modules>>
<<bsmo-command>>
#+end_src

**** 12 nodes
#+begin_src bash :dir sol-mpi-wk/12/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-wk/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<bsmo-name>>
<<kura-fix>>
<<modules>>
<<bsmo-command>>
#+end_src

** BS-SOLCTRA MPI+OpenMP Strong Scaling

*** Job Name
#+begin_src bash :noweb-ref bsms-name
#SBATCH --job-name solc-cpp-st
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref bsms-command
export OMP_NUM_THREADS=${SLURM_NTASKS_PER_NODE}
export OMP_SCHEDULE=dynamic
TOTAL_PARTICLES=$((12*2560))
REPETITIONS=10
for (( i = 0; i < ${REPETITIONS}; i++))
do
    srun -n ${SLURM_NNODES}\
	    ./bs-solctra-multinode\
	    -length ${TOTAL_PARTICLES}\
	    -particles input_big.txt\
	    -id ${SLURM_JOB_ID}${i}\
	    -resource resources/\
	    -mode 1\
	    -magnetic_prof 0 100 0 2\
	    -print_typef 1\
	    -steps 1000
done
#+end_src

*** Assemble Slurm files for strong scaling and copy files

**** 1 node

#+begin_src bash :dir sol-mpi-st/1/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-st/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<bsms-name>>
<<kura-fix>>
<<modules>>
<<bsms-command>>
#+end_src

**** 2 nodes

#+begin_src bash :dir sol-mpi-st/2/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-st/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<bsms-name>>
<<kura-fix>>
<<modules>>
<<bsms-command>>
#+end_src

**** 4 nodes

#+begin_src bash :dir sol-mpi-st/4/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-st/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<bsms-name>>
<<kura-fix>>
<<modules>>
<<bsms-command>>
#+end_src

**** 8 nodes
#+begin_src bash :dir sol-mpi-st/8/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-st/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<bsms-name>>
<<kura-fix>>
<<modules>>
<<bsms-command>>
#+end_src

**** 12 nodes
#+begin_src bash :dir sol-mpi-st/12/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_1000.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-mpi-st/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<bsms-name>>
<<kura-fix>>
<<modules>>
<<bsms-command>>
#+end_src

** BS-SOLCTRA MPI+Rayon Weak Scaling
*** Job Name

#+begin_src bash :noweb-ref bsrw-name
#SBATCH --job-name solc-rust-ws
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref bsrw-command
export RAYON_NUM_THREADS=${SLURM_NTASKS_PER_NODE}
TOTAL_PARTICLES=$((${SLURM_NNODES}*2560))
REPETITIONS=10
for (( i = 0; i < ${REPETITIONS}; i++))
do
    RUST_LOG=info srun -n ${SLURM_NNODES}\
		  ./bs-solctra-rs\
		  --num-particles ${TOTAL_PARTICLES}\
		  --particles-file input_big.csv\
		  --resource-path resources/\
		  --mode 1\
		  --magprof 0\
		  --steps 1000\
		  -w 10000\
		  --output results_${SLURM_JOBID}${i}
done
#+end_src

*** Assemble Slurm files for weak scaling and copy files
**** 1 node

#+begin_src bash :dir sol-rst-wk/1/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-wk/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<bsrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrw-command>>
#+end_src

**** 2 node

#+begin_src bash :dir sol-rst-wk/2/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-wk/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<bsrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrw-command>>
#+end_src

**** 4 nodes

#+begin_src bash :dir sol-rst-wk/4/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-wk/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<bsrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrw-command>>
#+end_src

**** 8 nodes

#+begin_src bash :dir sol-rst-wk/8/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-wk/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<bsrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrw-command>>
#+end_src

**** 12 nodes

#+begin_src bash :dir sol-rst-wk/12/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-wk/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12

<<bsrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrw-command>>
#+end_src

** BS-SOLCTRA MPI+Rayon Strong Scaling

*** Job Name

#+begin_src bash :noweb-ref bsrs-name
#SBATCH --job-name solc-rust-st
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref bsrs-command
export RAYON_NUM_THREADS=${SLURM_NTASKS_PER_NODE}
TOTAL_PARTICLES=$((12*2560))
REPETITIONS=10
for (( i = 0; i < ${REPETITIONS}; i++))
do
    RUST_LOG=debug srun -n ${SLURM_NNODES}\
		  ./bs-solctra-rs\
		  --num-particles ${TOTAL_PARTICLES}\
		  --particles-file input_big.csv\
		  --resource-path resources/\
		  --mode 1\
		  --magprof 0\
		  --steps 1000\
		  -w 10000\
		  --output results_${SLURM_JOBID}${i}
done
#+end_src

*** Assemble Slurm files for weak scaling and copy files

**** 1 node

#+begin_src bash :dir sol-rst-st/1/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-st/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<bsrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrs-command>>
#+end_src

**** 2 node

#+begin_src bash :dir sol-rst-st/2/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-st/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<bsrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrs-command>>
#+end_src

**** 4 nodes

#+begin_src bash :dir sol-rst-st/4/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-st/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<bsrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrs-command>>
#+end_src

**** 8 nodes

#+begin_src bash :dir sol-rst-st/8/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-st/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<bsrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrs-command>>
#+end_src

**** 12 nodes

#+begin_src bash :dir sol-rst-st/12/ :mkdirp yes
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_1000.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle sol-rst-st/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12

<<bsrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<bsrs-command>>
#+end_src

** PIC C Weak Scaling
*** Job Name
#+begin_src bash :noweb-ref piccw-name
#SBATCH --job-name pic-c-ws
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref piccw-command
export OMP_NUM_THREADS=${SLURM_NTASKS_PER_NODE}
export OMP_SCHEDULE=dynamic
export REPETITIONS=10
TOTAL_STEPS=100
TOTAL_PARTICLES=$((${SLURM_NNODES}*102400))
for (( i = 0; i < ${REPETITIONS}; i++))
do
    echo "~rep: ${i}~" >&2
    echo "###################################"
    echo "GEOMETRIC" >&2
    time srun -n ${SLURM_NNODES}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 2\
	    GEOMETRIC 0.99
    echo "###################################"
    echo "SINUSOIDAL" >&2
    time srun -n ${SLURM_NNODES}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    0 1\
	    SINUSOIDAL
    echo "###################################"
    echo "LINEAR" >&2
    time srun -n ${SLURM_NNODES}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 0\
	    LINEAR\
	    1.0\
	    3.0
    echo "###################################"
    echo "PATCH" >&2
    time srun -n ${SLURM_NNODES}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 0\
	    PATCH\
	    0 200\
	    100 200
done
#+end_src

*** Assemble Slurm files for weak scaling and copy files

**** 1 node

#+begin_src bash :dir pic-c-wk/1/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<piccw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccw-command>>
#+end_src

**** 2 nodes

#+begin_src bash :dir pic-c-wk/2/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<piccw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccw-command>>
#+end_src

**** 4 nodes

#+begin_src bash :dir pic-c-wk/4/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<piccw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccw-command>>
#+end_src


**** 8 nodes

#+begin_src bash :dir pic-c-wk/8/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<piccw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccw-command>>
#+end_src


**** 12 nodes

#+begin_src bash :dir pic-c-wk/12/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<piccw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccw-command>>
#+end_src

** PIC C Weak Scaling Pure MPI
*** Job Name
#+begin_src bash :noweb-ref piccwp-name
#SBATCH --job-name pic-c-ws-pm
#+end_src

*** Execution commands
#+begin_src bash :noweb-ref piccwp-command
export REPETITIONS=10
TOTAL_STEPS=100
TOTAL_PARTICLES=$((${SLURM_NTASKS}*102400))
for (( i = 0; i < ${REPETITIONS}; i++))
do
    echo "~rep: ${i}~" >&2
    echo "###################################"
    echo "GEOMETRIC" >&2
    time mpirun -n ${SLURM_NTASKS}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 2\
	    GEOMETRIC 0.99
    echo "###################################"
    echo "SINUSOIDAL" >&2
    time mpirun -n ${SLURM_NTASKS}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    0 1\
	    SINUSOIDAL
    echo "###################################"
    echo "LINEAR" >&2
    time mpirun -n ${SLURM_NTASKS}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 0\
	    LINEAR\
	    1.0\
	    3.0
    echo "###################################"
    echo "PATCH" >&2
    time mpirun -n ${SLURM_NTASKS}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 0\
	    PATCH\
	    0 200\
	    100 200
done
#+end_src
*** Assemble Slurm files for weak scaling and copy files

**** 1 node

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-p/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<piccwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwp-command>>
#+end_src

**** 2 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-p/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<piccwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwp-command>>
#+end_src

**** 4 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-p/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<piccwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwp-command>>
#+end_src


**** 8 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-p/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<piccwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwp-command>>
#+end_src


**** 12 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-p/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<piccwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwp-command>>
#+end_src

** PIC C Strong Scaling
*** Job Name
#+begin_src bash :noweb-ref piccs-name
#SBATCH --job-name pic-c-st
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref piccs-command
export OMP_NUM_THREADS=${SLURM_NTASKS_PER_NODE}
export OMP_SCHEDULE=dynamic
export REPETITIONS=10
TOTAL_STEPS=100
TOTAL_PARTICLES=$((12*102400))
for (( i = 0; i < ${REPETITIONS}; i++))
do
    echo "~rep: ${i}~" >&2
    echo "###################################"
    echo "GEOMETRIC" >&2
    time srun -n ${SLURM_NNODES}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 2\
	    GEOMETRIC 0.99
    echo "###################################"
    echo "SINUSOIDAL" >&2
    time srun -n ${SLURM_NNODES}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    0 1\
	    SINUSOIDAL
    echo "###################################"
    echo "LINEAR" >&2
    time srun -n ${SLURM_NNODES}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 0\
	    LINEAR\
	    1.0\
	    3.0
    echo "###################################"
    echo "PATCH" >&2
    time srun -n ${SLURM_NNODES}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 0\
	    PATCH\
	    0\
	    200\
	    100\
	    200
done
#+end_src

*** Assemble Slurm files for strong scaling and copy files

**** 1 node

#+begin_src bash :dir pic-c-st/1/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<piccs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccs-command>>
#+end_src

**** 2 nodes

#+begin_src bash :dir pic-c-st/2/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<piccs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccs-command>>
#+end_src

**** 4 nodes

#+begin_src bash :dir pic-c-st/4/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<piccs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccs-command>>
#+end_src

**** 8 nodes

#+begin_src bash :dir pic-c-st/8/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<piccs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccs-command>>
#+end_src

**** 12 nodes

#+begin_src bash :dir pic-c-st/12/ :mkdirp yes
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
#+end_src

#+RESULTS:


#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<piccs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccs-command>>
#+end_src

** PIC C Strong Scaling Pure MPI
*** Job Name
#+begin_src bash :noweb-ref piccsp-name
#SBATCH --job-name pic-c-sc-pm
#+end_src

*** Execution commands
#+begin_src bash :noweb-ref piccsp-command
export REPETITIONS=10
TOTAL_STEPS=100
TOTAL_PARTICLES=$((12*102400))
for (( i = 0; i < ${REPETITIONS}; i++))
do
    echo "~rep: ${i}~" >&2
    echo "###################################"
    echo "GEOMETRIC" >&2
    time mpirun -n ${SLURM_NTASKS}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 2\
	    GEOMETRIC 0.99
    echo "###################################"
    echo "SINUSOIDAL" >&2
    time mpirun -n ${SLURM_NTASKS}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    0 1\
	    SINUSOIDAL
    echo "###################################"
    echo "LINEAR" >&2
    time mpirun -n ${SLURM_NTASKS}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 0\
	    LINEAR\
	    1.0\
	    3.0
    echo "###################################"
    echo "PATCH" >&2
    time mpirun -n ${SLURM_NTASKS}\
	    ./pic\
	    ${TOTAL_STEPS}\
	    1000\
	    ${TOTAL_PARTICLES}\
	    1 0\
	    PATCH\
	    0 200\
	    100 200
done
#+end_src

*** Assemble Slurm files for strong scaling and copy files

**** 1 node

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st-p/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<piccsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccsp-command>>
#+end_src

**** 2 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st-p/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<piccsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccsp-command>>
#+end_src

**** 4 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st-p/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<piccsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccsp-command>>
#+end_src

**** 8 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st-p/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<piccsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccsp-command>>
#+end_src

**** 12 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-st-p/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<piccsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccsp-command>>
#+end_src

** PIC RUST Weak Scaling
*** Job Name
#+begin_src bash :noweb-ref picrw-name
#SBATCH --job-name pic-r-ws
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref picrw-command
export RAYON_NUM_THREADS=${SLURM_NTASKS_PER_NODE}
REPETITIONS=10
TOTAL_STEPS=100
TOTAL_PARTICLES=$((${SLURM_NNODES}*102400))
for (( i = 0; i < ${REPETITIONS}; i++))
do
    echo "~rep: ${i}~" >&2
    echo "###################################"
    echo "GEOMETRIC" >&2
    time srun -n ${SLURM_NNODES}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 2\
	 geometric\
	 -a 0.99
    echo "###################################"
    echo "SINUSOIDAL" >&2
    time srun -n ${SLURM_NNODES}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 0 -v 1\
	 sinusoidal
    echo "###################################"
    echo "LINEAR" >&2
    time srun -n ${SLURM_NNODES}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 0\
	 linear\
	 -n 1.0\
	 -c 3.0
    echo "###################################"
    echo "PATCH" >&2
    time srun -n ${SLURM_NNODES}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 0\
	 patch\
	 --xleft 0 --xright 200\
	 --ybottom 100 --ytop 200
done
#+end_src

*** Assemble Slurm files for weak scaling and copy files

**** 1 node

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<picrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrw-command>>
#+end_src

**** 2 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<picrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrw-command>>
#+end_src

**** 4 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<picrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrw-command>>
#+end_src

**** 8 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<picrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrw-command>>
#+end_src

**** 12 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<picrw-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrw-command>>
#+end_src

** PIC RUST Weak Scaling Pure MPI
*** Job Name
#+begin_src bash :noweb-ref picrwp-name
#SBATCH --job-name pic-r-ws-p
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref picrwp-command
REPETITIONS=10
TOTAL_STEPS=100
TOTAL_PARTICLES=$((${SLURM_NTASKS}*102400))
for (( i = 0; i < ${REPETITIONS}; i++))
do
    echo "~rep: ${i}~" >&2
    echo "###################################"
    echo "GEOMETRIC" >&2
    time mpirun -n ${SLURM_NTASKS}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 2\
	 geometric\
	 -a 0.99
    echo "###################################"
    echo "SINUSOIDAL" >&2
    time mpirun -n ${SLURM_NTASKS}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 0 -v 1\
	 sinusoidal
    echo "###################################"
    echo "LINEAR" >&2
    time mpirun -n ${SLURM_NTASKS}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 0\
	 linear\
	 -n 1.0\
	 -c 3.0
    echo "###################################"
    echo "PATCH" >&2
    time mpirun -n ${SLURM_NTASKS}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 0\
	 patch\
	 --xleft 0 --xright 200\
	 --ybottom 100 --ytop 200
done
#+end_src

*** Assemble Slurm files for weak scaling and copy files

**** 1 node

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-p/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<picrwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwp-command>>
#+end_src

**** 2 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-p/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<picrwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwp-command>>
#+end_src

**** 4 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-p/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<picrwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwp-command>>
#+end_src

**** 8 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-p/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<picrwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwp-command>>
#+end_src

**** 12 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-p/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<picrwp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwp-command>>
#+end_src

** PIC RUST Strong Scaling
*** Job Name
#+begin_src bash :noweb-ref picrs-name
#SBATCH --job-name pic-r-st
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref picrs-command
export RAYON_NUM_THREADS=${SLURM_NTASKS_PER_NODE}
REPETITIONS=10
TOTAL_STEPS=100
TOTAL_PARTICLES=$((12*102400))
for (( i = 0; i < ${REPETITIONS}; i++))
do
    echo "~rep: ${i}~" >&2
    echo "###################################"
    echo "GEOMETRIC" >&2
    time srun -n ${SLURM_NNODES}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 2\
	 geometric\
	 -a 0.99
    echo "###################################"
    echo "SINUSOIDAL" >&2
    time srun -n ${SLURM_NNODES}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 0 -v 1\
	 sinusoidal
    echo "###################################"
    echo "LINEAR" >&2
    time srun -n ${SLURM_NNODES}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 0\
	 linear\
	 -n 1.0\
	 -c 3.0
    echo "###################################"
    echo "PATCH" >&2
    time srun -n ${SLURM_NNODES}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 0\
	 patch\
	 --xleft 0 --xright 200\
	 --ybottom 100 --ytop 200
done
#+end_src

*** Assemble Slurm files for weak scaling and copy files

**** 1 node

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<picrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrs-command>>
#+end_src

**** 2 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<picrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrs-command>>
#+end_src

**** 4 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<picrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrs-command>>
#+end_src

**** 8 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<picrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrs-command>>
#+end_src

**** 12 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<picrs-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrs-command>>
#+end_src

** PIC RUST Strong Scaling Pure MPI
*** Job Name
#+begin_src bash :noweb-ref picrsp-name
#SBATCH --job-name pic-r-st-p
#+end_src

*** Execution commands

#+begin_src bash :noweb-ref picrsp-command
REPETITIONS=10
TOTAL_STEPS=100
TOTAL_PARTICLES=$((12*102400))
for (( i = 0; i < ${REPETITIONS}; i++))
do
    echo "~rep: ${i}~" >&2
    echo "###################################"
    echo "GEOMETRIC" >&2
    time mpirun -n ${SLURM_NTASKS}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 2\
	 geometric\
	 -a 0.99
    echo "###################################"
    echo "SINUSOIDAL" >&2
    time mpirun -n ${SLURM_NTASKS}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 0 -v 1\
	 sinusoidal
    echo "###################################"
    echo "LINEAR" >&2
    time mpirun -n ${SLURM_NTASKS}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 0\
	 linear\
	 -n 1.0\
	 -c 3.0
    echo "###################################"
    echo "PATCH" >&2
    time mpirun -n ${SLURM_NTASKS}\
	 ./pic-mpi\
	 -i ${TOTAL_STEPS}\
	 -g 1000\
	 -t ${TOTAL_PARTICLES}\
	 -p 1 -v 0\
	 patch\
	 --xleft 0 --xright 200\
	 --ybottom 100 --ytop 200
done
#+end_src

*** Assemble Slurm files for strong scaling and copy files

**** 1 node

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st-p/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<picrsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrsp-command>>
#+end_src

**** 2 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st-p/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<picrsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrsp-command>>
#+end_src

**** 4 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st-p/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<picrsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrsp-command>>
#+end_src

**** 8 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st-p/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<picrsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrsp-command>>
#+end_src

**** 12 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-st-p/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<picrsp-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrsp-command>>
#+end_src

** Load Imbalance

*** Compiling for profiling

**** Requirements

- MPICH 3.3.2
- gcc 9.3.0
- TAU (Installed from source)
- PDToolkit (Installed from source)

**** Compiling C version
#+begin_src bash :tangle Kernels/common/make.defs
TAU_DIR=/work/casch/tau-2.34.1/x86_64
CC=gcc -std=c11 -pthread
CXX=g++ -std=c++20 -pthread -fmax-errors=1
DEFAULT_OPT_FLAGS=-O0 -g -mtune=native -ffast-math
# DEFAULT_OPT_FLAGS+=-g3
DEFAULT_OPT_FLAGS+=-Wall
MPIDIR=/opt/tools/mpich-3.3.2-gcc-9.3.0
MPICC=${TAU_DIR}/bin/tau_cc.sh
MPICXX=${TAU_DIR}/bin/tau_cxx.sh
MPIFORT=mpifort
# MPICC=${MPIDIR}/bin/mpicc
# MPICXX=${MPIDIR}/bin/mpicxx
# MPIFORT=${MPIDIR}/bin/mpifort
# MPIINC=-I${MPIDIR}/include
# MPILIB=-L${MPIDIR}/lib -Wl,-rpath -Wl,${MPIDIR}/lib -lmpi_usempif08 -lmpi
#+end_src

#+begin_src bash :results output :exports both :dir Kernels/MPI1/PIC-static
module load mpich/3.3.2-gcc-9.3.0 gcc/9.3.0
make clean
TAU_MAKEFILE=/work/casch/tau-2.34.1/x86_64/lib/Makefile.tau-mpi-pdt make pic
#+end_src

**** Compiling Rust Version
#+begin_src bash :results output :exports both :dir Kernels/RUST/pic-mpi
export TAU_MAKEFILE=/work/casch/tau-2.34.1/x86_64/lib/Makefile.tau-mpi-pdt
export TAU_COMPILER=/work/casch/tau-2.34.1/x86_64/bin/tau_cc.sh
export RUSTFLAGS="-C linker=/work/casch/tau-2.34.1/x86_64/bin/tau_cc.sh -C link-arg=-Wl,-rpath,/work/casch/tau-2.34.1/x86_64/lib"
cargo build
#+end_src

**** PIC C Weak Scaling Pure MPI Imbalance
***** Job Name
#+begin_src bash :noweb-ref piccwi-name
#SBATCH --job-name pic-c-ws-im
#+end_src

***** Execution commands
#+begin_src bash :noweb-ref piccwi-command
TOTAL_STEPS=100
TOTAL_PARTICLES=$((${SLURM_NTASKS}*102400))
echo "###################################"
echo "GEOMETRIC" >&2
mpirun -n ${SLURM_NTASKS}\
     ./pic\
     ${TOTAL_STEPS}\
     1000\
     ${TOTAL_PARTICLES}\
     1 2\
     GEOMETRIC 0.99
tar -czf geometric.tar.gz profile.*
rm profile.*
echo "###################################"
echo "SINUSOIDAL" >&2
mpirun -n ${SLURM_NTASKS}\
     ./pic\
     ${TOTAL_STEPS}\
     1000\
     ${TOTAL_PARTICLES}\
     0 1\
     SINUSOIDAL
tar -czf sinusoidal.tar.gz profile.*
rm profile.*
echo "###################################"
echo "LINEAR" >&2
mpirun -n ${SLURM_NTASKS}\
     ./pic\
     ${TOTAL_STEPS}\
     1000\
     ${TOTAL_PARTICLES}\
     1 0\
     LINEAR\
     1.0\
     3.0
tar -czf linear.tar.gz profile.*
rm profile.*
echo "###################################"
echo "PATCH" >&2
mpirun -n ${SLURM_NTASKS}\
     ./pic\
     ${TOTAL_STEPS}\
     1000\
     ${TOTAL_PARTICLES}\
     1 0\
     PATCH\
     0 200\
     100 200
tar -czf patch.tar.gz profile.*
rm profile.*
#+end_src
***** Assemble Slurm files for weak scaling and copy files

****** 1 node

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-i/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<piccwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwi-command>>
#+end_src

****** 2 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-i/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<piccwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwi-command>>
#+end_src

****** 4 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-i/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<piccwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwi-command>>
#+end_src


****** 8 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-i/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<piccwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwi-command>>
#+end_src


****** 12 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-c-wk-i/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<piccwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<piccwi-command>>
#+end_src

**** PIC RUST Weak Scaling Pure MPI Imbalance
***** Job Name
#+begin_src bash :noweb-ref picrwi-name
#SBATCH --job-name pic-r-ws-i
#+end_src

***** Execution commands

#+begin_src bash :noweb-ref picrwi-command
TOTAL_STEPS=100
TOTAL_PARTICLES=$((${SLURM_NTASKS}*102400))
echo "###################################"
echo "GEOMETRIC" >&2
mpirun -n ${SLURM_NTASKS}\
     ./pic-mpi\
     -i ${TOTAL_STEPS}\
     -g 1000\
     -t ${TOTAL_PARTICLES}\
     -p 1 -v 2\
     geometric\
     -a 0.99
tar -czf geometric.tar.gz profile.*
rm profile.*
echo "###################################"
echo "SINUSOIDAL" >&2
mpirun -n ${SLURM_NTASKS}\
     ./pic-mpi\
     -i ${TOTAL_STEPS}\
     -g 1000\
     -t ${TOTAL_PARTICLES}\
     -p 0 -v 1\
     sinusoidal
tar -czf sinusoidal.tar.gz profile.*
rm profile.*
echo "###################################"
echo "LINEAR" >&2
mpirun -n ${SLURM_NTASKS}\
     ./pic-mpi\
     -i ${TOTAL_STEPS}\
     -g 1000\
     -t ${TOTAL_PARTICLES}\
     -p 1 -v 0\
     linear\
     -n 1.0\
     -c 3.0
tar -czf linear.tar.gz profile.*
rm profile.*
echo "###################################"
echo "PATCH" >&2
mpirun -n ${SLURM_NTASKS}\
     ./pic-mpi\
     -i ${TOTAL_STEPS}\
     -g 1000\
     -t ${TOTAL_PARTICLES}\
     -p 1 -v 0\
     patch\
     --xleft 0 --xright 200\
     --ybottom 100 --ytop 200
tar -czf patch.tar.gz profile.*
rm profile.*
#+end_src

***** Assemble Slurm files for weak scaling and copy files

****** 1 node

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-i/1/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 1
<<picrwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwi-command>>
#+end_src

****** 2 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-i/2/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 2
<<picrwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwi-command>>
#+end_src

****** 4 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-i/4/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 4
<<picrwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwi-command>>
#+end_src

****** 8 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-i/8/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 8
<<picrwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwi-command>>
#+end_src

****** 12 nodes

#+begin_src bash :shebang #!/bin/bash :tangle pic-r-wk-i/12/run.slurm :mkdirp yes :noweb yes
<<header>>
#SBATCH --nodes 12
<<picrwi-name>>
<<kura-fix>>
<<modules>>
source /work/casch/spack/share/spack/setup-env.sh
spack env activate rustdev
<<picrwi-command>>
#+end_src


* Submit experiments
** BS-SOLCTRA MPI+OpenMP Weak Scaling
*** 1 node

#+begin_src bash :dir sol-mpi-wk/1
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235410

*** 2 nodes

#+begin_src bash :dir sol-mpi-wk/2
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235411

*** 4 nodes

#+begin_src bash :dir sol-mpi-wk/4
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235412

*** 8 nodes

#+begin_src bash :dir sol-mpi-wk/8
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235413

*** 12 nodes
#+begin_src bash :dir sol-mpi-wk/12
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235414

** BS-SOLCTRA MPI+OpenMP Strong Scaling

*** 1 node

#+begin_src bash :dir sol-mpi-st/1
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235415

*** 2 nodes

#+begin_src bash :dir sol-mpi-st/2
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235416

*** 4 nodes

#+begin_src bash :dir sol-mpi-st/4
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235417

*** 8 nodes

#+begin_src bash :dir sol-mpi-st/8
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235418

*** 12 nodes

#+begin_src bash :dir sol-mpi-st/12
rm -rf results_* *.err *.out stats.csv stdout*
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/input_big.txt .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-implementations/results/bs-solctra-multinode .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235419

** BS-SOLCTRA Rust MPI+Rayon Weak Scaling
*** 1 node

#+begin_src bash :dir sol-rst-wk/1
rm -r results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235507

*** 2 nodes

#+begin_src bash :dir sol-rst-wk/2
rm -r results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235508

*** 4 nodes

#+begin_src bash :dir sol-rst-wk/4
rm -rf results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235509

*** 8 nodes

#+begin_src bash :dir sol-rst-wk/8
rm -rf results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235510

*** 12 nodes

#+begin_src bash :dir sol-rst-wk/12
rm -rf results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235511

** BS-SOLCTRA Rust MPI+Rayon Strong Scaling
*** 1 node

#+begin_src bash :dir sol-rst-st/1
rm -r results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235512

*** 2 nodes

#+begin_src bash :dir sol-rst-st/2
rm -rf results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235513

*** 4 nodes
#+begin_src bash :dir sol-rst-st/4
rm -rf results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235514

*** 8 nodes

#+begin_src bash :dir sol-rst-st/8
rm -rf results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235515

*** 12 nodes

#+begin_src bash :dir sol-rst-st/12
rm -rf results_* *.err *.out
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/input_big.csv .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/tests/test-resources/resources .
ln -sf ~/RustMPIExperiments/bs-solctra-mpi-rs/target/release/bs-solctra-rs .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235516

** PIC C Weak Scaling

*** 1 node

#+begin_src bash :dir pic-c-wk/1
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235467

*** 2 nodes

#+begin_src bash :dir pic-c-wk/2
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235468

*** 4 nodes

#+begin_src bash :dir pic-c-wk/4
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235469

*** 8 nodes

#+begin_src bash :dir pic-c-wk/8
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235470

*** 12 nodes
#+begin_src bash :dir pic-c-wk/12
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235471
** PIC C Weak Pure MPI Scaling

*** 1 node

#+begin_src bash :dir pic-c-wk-p/1
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235704

*** 2 nodes

#+begin_src bash :dir pic-c-wk-p/2
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235705

*** 4 nodes

#+begin_src bash :dir pic-c-wk-p/4
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235706

*** 8 nodes

#+begin_src bash :dir pic-c-wk-p/8
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235707

*** 12 nodes
#+begin_src bash :dir pic-c-wk-p/12
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235708

** PIC C Strong Scaling

*** 1 node

#+begin_src bash :dir pic-c-st/1
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235472

*** 2 nodes

#+begin_src bash :dir pic-c-st/2
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235473

*** 4 nodes

#+begin_src bash :dir pic-c-st/4
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235474

*** 8 nodes

#+begin_src bash :dir pic-c-st/8
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235475

*** 12 nodes

#+begin_src bash :dir pic-c-st/12
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235476

** PIC C Strong Pure MPI Scaling

*** 1 node

#+begin_src bash :dir pic-c-st-p/1
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235714

*** 2 nodes

#+begin_src bash :dir pic-c-st-p/2
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235715

*** 4 nodes

#+begin_src bash :dir pic-c-st-p/4
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235716

*** 8 nodes

#+begin_src bash :dir pic-c-st-p/8
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235717

*** 12 nodes
#+begin_src bash :dir pic-c-st-p/12
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/MPI1/PIC-static/pic .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235718

** PIC RUST Weak Scaling

*** 1 node

#+begin_src bash :dir pic-r-wk/1
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235477

*** 2 nodes

#+begin_src bash :dir pic-r-wk/2
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235478

*** 4 nodes

#+begin_src bash :dir pic-r-wk/4
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235479

*** 8 nodes

#+begin_src bash :dir pic-r-wk/8
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235480

*** 12 nodes
#+begin_src bash :dir pic-r-wk/12
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235481

** PIC RUST Weak Pure MPI Scaling

*** 1 node

#+begin_src bash :dir pic-r-wk-p/1
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235709

*** 2 nodes

#+begin_src bash :dir pic-r-wk-p/2
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235710

*** 4 nodes

#+begin_src bash :dir pic-r-wk-p/4
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235711

*** 8 nodes

#+begin_src bash :dir pic-r-wk-p/8
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235712

*** 12 nodes
#+begin_src bash :dir pic-r-wk-p/12
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235713

** PIC RUST Strong Scaling

*** 1 node

#+begin_src bash :dir pic-r-st/1
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235482

*** 2 nodes

#+begin_src bash :dir pic-r-st/2
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235483

*** 4 nodes

#+begin_src bash :dir pic-r-st/4
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235484

*** 8 nodes

#+begin_src bash :dir pic-r-st/8
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235485

*** 12 nodes
#+begin_src bash :dir pic-r-st/12
rm *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235486

pppp
#+RESULTS:
: Submitted batch job 235167

** PIC RUST Strong Pure MPI Scaling

*** 1 node

#+begin_src bash :dir pic-r-st-p/1
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235719

*** 2 nodes

#+begin_src bash :dir pic-r-st-p/2
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235720

*** 4 nodes

#+begin_src bash :dir pic-r-st-p/4
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235721

*** 8 nodes

#+begin_src bash :dir pic-r-st-p/8
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235722

*** 12 nodes
#+begin_src bash :dir pic-r-st-p/12
rm -f *.err *.out
ln -sf ~/RustMPIExperiments/Kernels/RUST/pic-mpi/target/release/pic-mpi .
sbatch run.slurm
#+end_src

#+RESULTS:
: Submitted batch job 235723

* Results
** BS-SOLCTRA weak scaling

#+begin_src bash :dir sol-mpi-wk
cat */stats.csv | awk -F ',' ' {print "c++," $2/256 "," $2 "," $6} ' > results.csv
#+end_src

#+RESULTS:

#+begin_src bash :dir sol-rst-wk
cat */solc-rust-ws_*.err | csplit - '/.*Starting.*/' '{*}' -s
grep -e "Total" -e "Simulation" xx* | awk -F ']' ' { print $2 } ' > results_partial.out
rm xx*
csplit results_partial.out '/Total.*/' '{*}' -s
rm results_partial.out
FILES=`ls xx*`
for file in $FILES
do
    awk -F ':' ' { print $2 } ' $file | tr '\n' , | awk -F ',' ' { print "rust," $1 "," $1 * 256 "," $2 } ' >> results.csv
done
sed -i 's/\ //g' results.csv
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash
cat sol-mpi-wk/results.csv sol-rst-wk/results.csv > solctra_weak.csv
#+end_src

#+RESULTS:

** BS-SOLCTRA Strong scaling
#+begin_src bash :dir sol-mpi-st
cat */*.out | csplit - '/.*Communicator.*/' '{*}' -s
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
    grep -e "Communicator" -e "Particles=" -e "Total" $file | awk -F '=' ' { print $2 } ' \
	| sed -e 's/\[//' -e 's/]\.//' | tr '\n' , | awk -F ',' ' { print "c++," $1 "," $2 "," $3 } ' >> results.csv
done
# | awk -F '=' ' { print $2 } ' | sed -e 's/\[//' -e 's/\]//' -e 's/\.//'
rm xx*
#+end_src

#+RESULTS:
| c++ | 12 | 3072 | 55.047 |
| c++ | 12 | 3072 | 55.145 |
| c++ | 12 | 3072 |  55.01 |
| c++ | 12 | 3072 | 55.084 |
| c++ | 12 | 3072 | 55.098 |
| c++ | 12 | 3072 | 55.071 |
| c++ | 12 | 3072 | 55.126 |
| c++ | 12 | 3072 | 55.142 |
| c++ | 12 | 3072 | 55.037 |
| c++ | 12 | 3072 | 55.144 |
| c++ |  1 | 3072 | 24.241 |
| c++ |  1 | 3072 | 24.081 |
| c++ |  1 | 3072 | 24.968 |
| c++ |  1 | 3072 | 24.222 |
| c++ |  1 | 3072 | 24.166 |
| c++ |  1 | 3072 | 24.214 |
| c++ |  1 | 3072 | 24.249 |
| c++ |  1 | 3072 | 24.212 |
| c++ |  1 | 3072 | 24.317 |
| c++ |  1 | 3072 | 24.194 |
| c++ |  2 | 3072 | 24.507 |
| c++ |  2 | 3072 |  24.56 |
| c++ |  2 | 3072 | 25.115 |
| c++ |  2 | 3072 | 24.447 |
| c++ |  2 | 3072 | 24.414 |
| c++ |  2 | 3072 | 25.117 |
| c++ |  2 | 3072 | 24.486 |
| c++ |  2 | 3072 | 24.519 |
| c++ |  2 | 3072 | 24.531 |
| c++ |  2 | 3072 | 24.584 |
| c++ |  4 | 3072 | 32.078 |
| c++ |  4 | 3072 | 32.198 |
| c++ |  4 | 3072 | 32.116 |
| c++ |  4 | 3072 | 32.113 |
| c++ |  4 | 3072 | 32.208 |
| c++ |  4 | 3072 | 32.115 |
| c++ |  4 | 3072 | 32.226 |
| c++ |  4 | 3072 |  32.16 |
| c++ |  4 | 3072 | 32.258 |
| c++ |  4 | 3072 | 32.094 |
| c++ |  8 | 3072 |  43.71 |
| c++ |  8 | 3072 | 43.651 |
| c++ |  8 | 3072 | 43.542 |
| c++ |  8 | 3072 | 43.672 |
| c++ |  8 | 3072 | 43.649 |
| c++ |  8 | 3072 | 44.033 |
| c++ |  8 | 3072 | 43.622 |
| c++ |  8 | 3072 | 43.917 |
| c++ |  8 | 3072 | 44.219 |
| c++ |  8 | 3072 | 43.739 |

#+begin_src bash :dir sol-rst-st
cat */solc-rust-st_*.err | csplit - '/.*Starting.*/' '{*}' -s
grep -e "Total" -e "Simulation" xx* | awk -F ']' ' { print $2 } ' > results_partial.out
rm xx*
csplit results_partial.out '/Total.*/' '{*}' -s
rm results_partial.out
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
    awk -F ':' ' { print $2 } ' $file | tr '\n' , | awk -F ',' ' { print "rust," $1 "," 12*256 "," $2 } ' >> results.csv
done
sed -i 's/\ //g' results.csv
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash
cat sol-mpi-st/results.csv sol-rst-st/results.csv > solctra_strong.csv
#+end_src

#+RESULTS:

** PIC Weak scaling
#+begin_src bash :dir pic-c-wk
cat */*.out | csplit - '/.*#.*/' '{*}' -s
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
cat $file | tr ':' '=' | grep -e "Number of ranks" -e "Number of particles requested" -e "Rate" -e "Initialization mode" \
     | awk -F '=' ' { print $2 } ' | tr '\n' ',' | awk -F ',' ' { print "c++," $1 "," $2 "," $3 "," $4 } ' >> results.csv
done
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash :dir pic-r-wk
cat */*.out | csplit - '/.*#.*/' '{*}' -s
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
cat $file | tr ':' '=' | grep -e "Number of ranks" -e "Number of particles requested" -e "Rate" -e "Initialization mode" \
     | awk -F '=' ' { print $2 } ' | tr '\n' ',' | awk -F ',' ' { print "rust," $1 "," $2 "," $3 "," $4 } ' >> results.csv
done
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash
cat pic-c-wk/results.csv pic-r-wk/results.csv > pic-wk.csv
#+end_src

#+RESULTS:

** PIC Weak Scaling Pure MPI
#+begin_src bash :dir pic-c-wk-p
cat */*.out | csplit - '/.*#.*/' '{*}' -s
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
cat $file | tr ':' '=' | grep -e "Number of ranks" -e "Number of particles requested" -e "Rate" -e "Initialization mode" \
     | awk -F '=' ' { print $2 } ' | tr '\n' ',' | awk -F ',' ' { print "c++," $1/20 "," $1 "," $2 "," $3 "," $4 } ' >> results.csv
done
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash :dir pic-r-wk-p
cat */*.out | csplit - '/.*#.*/' '{*}' -s
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
cat $file | tr ':' '=' | grep -e "Number of ranks" -e "Number of particles requested" -e "Rate" -e "Initialization mode" \
     | awk -F '=' ' { print $2 } ' | tr '\n' ',' | awk -F ',' ' { print "rust," $1/20 "," $1 "," $2 "," $3 "," $4 } ' >> results.csv
done
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash
echo "lang,nodes,ranks,particles,init,rate" > pic-wk-pure.csv
cat pic-c-wk-p/results.csv pic-r-wk-p/results.csv >> pic-wk-pure.csv
#+end_src

#+RESULTS:

** PIC Strong scaling
#+begin_src bash :dir pic-c-st
cat */*.out | csplit - '/.*#.*/' '{*}' -s
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
cat $file | tr ':' '=' | grep -e "Number of ranks" -e "Number of particles requested" -e "Rate" -e "Initialization mode" \
     | awk -F '=' ' { print $2 } ' | tr '\n' ',' | awk -F ',' ' { print "c++," $1 "," $2 "," $3 "," $4 } ' >> results.csv
done
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash :dir pic-r-st
cat */*.out | csplit - '/.*#.*/' '{*}' -s
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
cat $file | tr ':' '=' | grep -e "Number of ranks" -e "Number of particles requested" -e "Rate" -e "Initialization mode" \
     | awk -F '=' ' { print $2 } ' | tr '\n' ',' | awk -F ',' ' { print "rust," $1 "," $2 "," $3 "," $4 } ' >> results.csv
done
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash
cat pic-c-st/results.csv pic-r-st/results.csv > pic-st.csv
#+end_src

#+RESULTS:

** PIC Strong scaling Pure MPI
#+begin_src bash :dir pic-c-st-p
cat */*.out | csplit - '/.*#.*/' '{*}' -s
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
cat $file | tr ':' '=' | grep -e "Number of ranks" -e "Number of particles requested" -e "Rate" -e "Initialization mode" \
     | awk -F '=' ' { print $2 } ' | tr '\n' ',' | awk -F ',' ' { print "c++," $1/20 "," $1 "," $2 "," $3 "," $4 } ' >> results.csv
done
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash :dir pic-r-st-p
cat */*.out | csplit - '/.*#.*/' '{*}' -s
FILES=`ls xx*`
rm -f results.csv
for file in $FILES
do
cat $file | tr ':' '=' | grep -e "Number of ranks" -e "Number of particles requested" -e "Rate" -e "Initialization mode" \
     | awk -F '=' ' { print $2 } ' | tr '\n' ',' | awk -F ',' ' { print "rust," $1/20 "," $1 "," $2 "," $3 "," $4 } ' >> results.csv
done
rm xx*
#+end_src

#+RESULTS:

#+begin_src bash
echo "lang,nodes,ranks,particles,init,rate" > pic-st-pure.csv
cat pic-c-st-p/results.csv pic-r-st-p/results.csv >> pic-st-pure.csv
#+end_src

#+RESULTS:
